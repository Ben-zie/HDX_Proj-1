---
title: "HDX_proj-1_main"
author: "Benjamin DAUTRIF"
date: "2023-10-26"
output:
  html_document:
    df_print: paged
---

# CONFIGURATION

This script installs from the *"configuration shunk"* the *"rhdx"* package. All interrogations of the HDX database relies on it. 

For more informations, see :    
https://gitlab.com/dickoa/rhdx

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)

# The easiest way to get dplyr is to install the whole tidyverse:
# install.packages("tidyverse")
# Alternatively, install just dplyr:
# install.packages("dplyr")
# install.packages('anytime')


# Install HDX package from Github :
# install.packages("remotes")
# remotes::install_gitlab("dickoa/rhdx")
# install.packages("RCurl")
# Loading packages :
library("rhdx")
library("dplyr")
library("RCurl")
library("purrr")
library("lubridate")
library('anytime')

```

## HDX Config :

Mendatory to configure RHDX package connexion with the HDX SERVER. 

For informations on the package, see man-page on : 

https://rdrr.io/github/dickoa/rhdx/man/

```{r conf, echo=TRUE}
set_rhdx_config(
  hdx_site = "prod",
#  hdx_key = NULL,
  read_only = TRUE,
#  hdx_config = NULL,
#  hdx_config_file = NULL,
#  configuration = NULL
)
```

To verify configuration : 

```{r , echo=TRUE}
# Configuration check :
  get_rhdx_config()
```

With result beeing : 
* <HDX Configuration> 
   HDX site: prod
   HDX site url: https://data.humdata.org
   HDX API key: *

## SEARCH IN MAIN SERVER

Simple (but evolutiv) search by *"key-word"*, specifying a *"limit"* for result-list. Below a "configuration panel" exposing variables :

```{r SEARCH MODULE, echo=TRUE}
# This shunck is a controle panel. Defin your variables :
Keyword = 'COD'

# Simple search with SEARCH_DATASETS function :
temp = search_datasets(Keyword,rows = 20)

GET_UNDER_DATES(temp)
```

## SEARCH IN RESULTS

Function returns a list of "HDX_datasets". Several criterias are then used to select in this results-pool, begining with date. 

N.B : to extract  informations from each dataset in the pool, a "*lapply*" structure easily exposes specific HDX functions (see [Manual](https://rdrr.io/github/dickoa/rhdx/man/)) :

```{r HDX FUNCTIONS, echo=TRUE}
# Module to perform date-specifi search in selection :
SEARCH_DATE <- function(selection){
    # Use a LAPPLY paterne for HDX-funtion. 
    # IMPORTANT : dates are here converted to DATE format (see ANYDATE)
    temp_date <- lapply(selection,
                       function(x){anydate(get_dataset_date(x))})
    # Each dataset has a [from ; to] pattenr. 
    # Here are two columns, converted to date-type :
    from_date = lapply(temp_date,
                       function(x){x[1]})
    to_date = lapply(temp_date,
                       function(x){anydate(x[2])})
    # That are binded by columns :
    temp_dates = cbind(from_date,to_date)
 
    # temp_dates[,1] = ymd(temp_dates[,1])
    # temp_dates[,2] = ymd(temp_dates[,2])  
    return(temp_dates)
}

SEARCH_DATES_UNDER = function(x){
    # Uses GET_DATE method to extract dates from datasets :
    temp_dates = SEARCH_DATE(x)
    # print given dates for choice of upper limit :
    print(temp_dates)
    # Get clipboard entry for upper limit :
    date_recherche = as.Date(readline("Enter DATE_MAX for selection (without \"\") : \n"))
    # Production of a mask for selection subset :
    mask_date = temp_dates[,1] < date_recherche
    # Subset in return :
    return(x[mask_date])
}

SEARCH_DATES_UPPER = function(x){
    # Uses GET_DATE method to extract dates from datasets :
    temp_dates = SEARCH_DATE(x)
    # print given dates for choice of lesser limit :
    print(temp_dates)
    # Get clipboard entry for lesser limit :
    date_recherche = as.Date(readline("Enter DATE_IN for selection (without \"\") : \n"))
    # Production of a mask for selection subset :
    # NOTE : 
    # Necessarily consider case where second date is NULL -> thus IFELSE structure
    mask_date = 
      ifelse(!is.na(temp_dates[, 2]), temp_dates[, 2], temp_dates[, 1]) > date_recherche
    # Subset in return :
    return(x[mask_date])
}
```

## Aggregate criterias

```{r SEARCH BY TAGS, echo=TRUE}
# Choose in results which medias to select for download :
SEARCH_TAGS = function(res){
  # Summarize TAGs presents in results :
  # CAUTION : see how "lapply" pattern exposes results to common HDX-Function :
  print(unique(unlist(lapply(res,
                       function(x){get_tags_names(x)}))))
  # Keyboard entry the chosen TAG(s) :
  clef_recherche = readline("Enter TAG for selection : \n")
  # Produce a mask with tag criteria
  mask = unlist(lapply(temp,
                       function(x){unlist(sum(get_tags_names(x)==clef_recherche))>=1}))
  print(mask)
  # Apply the mask to results for sub-selection : 
  temp_selected = res[mask]
  # Return sub-selection
  return(temp_selected)
}
```

```{r COD CONTENTS,echo=TRUE}
# Define Keywors : 
path = "C:/Users/Benjamin/Documents/GITHub/HDX_Proj-1/DATAs/From_HDX/COD/"
# NOTE : 'COD services API' is the specific name to resource in HDX. 
# In case of a problem, see nomenclatures and names in HDX directly.
#
# 1. Search online for HDX_Common Opperationnal Datasets (CODs) :
Keyword = 'COD Services API'
temp = search_datasets(Keyword,rows = 20)

# Navigate to resources : 
# 
# "CODServiceDeploymentStatus.xlsx"
x = temp %>% pluck(1) %>% get_resources() %>% pluck(5)
 
if(x$get_format()=="xlsx"){
  x$download(folder = path) 
}else{
  print("resource \"CODServiceDeploymentStatus.xlsx\" has changed : bad format")
}

# "Available COD Population Statistics through API access"
x = temp%>%pluck(1)%>%get_resources()%>%pluck(1)

if(x$get_format()=="json"){
  x$download(folder = path) 
}else{
  print("resource \"Available COD Population Statistics through API access\" has changed : bad format")
}

# "ArcGIS Server portfolio of services"
# HTML doc type : see "filename" below in "download function : erase param to get JSON)
x = temp%>%pluck(1)%>%get_resources()%>%pluck(3)

if(x$get_format()=="json"){
  x$download(folder = path,filename = "COD_External.html")
}else{
  print("resource \"ArcGIS Server portfolio of services\" has changed : bad format")
}
```

```{r COD UPDATE, echo=TRUE}

# Code to automatically download newer version of COD meta contents (list to make in text)
# is to be converted into a "get_all_resources" function : 

Keyword = 'COD Services API'
temp = search_datasets(Keyword,rows = 1)
COD_dataset_ID = temp[[1]]$data$id

# Pull dataset directly from ID :
COD_dataset = pull_dataset(COD_dataset_ID)
c = COD_dataset$get_resources()

# Can visit the Web-page :
# x$browse()
COD_resources_IDs =c()

for(i in seq(1,length(w))){
  COD_resources_IDs = append(data_IDs, COD_resources[[i]]$data$id)
}

lapply(COD_resources_IDs,function(x){download_resource(pull_resource(x),folder = path)})
```

```{r EXAMPLE, echo=TRUE}
# Destination folder 
folder = "C:/Users/Benjamin/Documents/GITHub/HDX_Proj-1/DATAs/From_HDX/"
result = res[[1]]%>%get_resources()
result[[2]]$download(folder = folder,filename = "PalestinianCommunities_WB_GS_Excel.xlsx")

stat_results = c()
districts_results = unique(palest$District)

prop.table(table(palest[palest$District == districts_list[1],]$Urban_Rurl))

# Search in selection by TAGs :
temp_1 = SEARCH_IN_SELECTION(temp)

# Access to ressources in result : 
temp_1[[1]]$get_resources()

# execute download :
download_resource(temp_1[[1]]$get_resources()[[1]],folder = folder)
```

