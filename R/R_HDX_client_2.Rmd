---
title: "HDX_proj-1_main"
author: "Benjamin DAUTRIF"
date: "2023-10-26"
output:
  html_document:
    df_print: paged
---

# CONFIGURATION

This script installs from the *"configuration shunk"* the *"rhdx"* package. All interrogations of the HDX database relies on it. 

For more informations, see :    
https://gitlab.com/dickoa/rhdx

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)

# The easiest way to get dplyr is to install the whole tidyverse:
# install.packages("tidyverse")
# Alternatively, install just dplyr:
# install.packages("dplyr")
# install.packages('anytime')


# Install HDX package from Github :
# install.packages("remotes")
# remotes::install_gitlab("dickoa/rhdx")
# install.packages("RCurl")
# Loading packages :
library("rhdx")
library("dplyr")
library("RCurl")
library("purrr")
library("lubridate")
library('anytime')

```

## HDX Config :

Mendatory to configure RHDX package connexion with the HDX SERVER. 

For informations on the package, see man-page on : 

https://rdrr.io/github/dickoa/rhdx/man/

```{r conf, echo=TRUE}
set_rhdx_config(
  hdx_site = "prod",
#  hdx_key = NULL,
  read_only = TRUE,
#  hdx_config = NULL,
#  hdx_config_file = NULL,
#  configuration = NULL
)
```

To verify configuration : 

```{r , echo=TRUE}
# Configuration check :
  get_rhdx_config()
```

With result beeing : 
* <HDX Configuration> 
   HDX site: prod
   HDX site url: https://data.humdata.org
   HDX API key: *

## SEARCH IN MAIN SERVER

Simple (but evolutiv) search by *"key-word"*, specifying a *"limit"* for result-list. Below a "configuration panel" exposing variables :

```{r SEARCH MODULE, message=FALSE, include=FALSE}
# This shunck is a controle panel. Defin your variables :
Keyword = 'ebola'

# Simple search with SEARCH_DATASETS function :
temp = search_datasets(Keyword,rows = 20)
```

## SEARCH IN RESULTS

"*search_datasets*" function returns a list of HDX_datasets objects. Several criterias can then be used to select in this pool (eg. dates, tags, organisation...). Each criteria corresponds to HDX-package functions, simply exposed by a "*lapply*" structure. 

See HDX [Manual](https://rdrr.io/github/dickoa/rhdx/man/) for more. 

### By date 

```{r HDX FUNCTIONS, echo=TRUE}
# Module to perform date-specifi search in selection :
SEARCH_DATE <- function(selection){
    # Use a LAPPLY paterne for HDX-funtion. 
    # IMPORTANT : dates are here converted to DATE format (see ANYDATE)
    temp_date <- lapply(selection,
                       function(x){anydate(get_dataset_date(x))})
    # Each dataset has a [from ; to] pattenr. 
    # Here are two columns, converted to date-type :
    from_date = lapply(temp_date,
                       function(x){x[1]})
    to_date = lapply(temp_date,
                       function(x){anydate(x[2])})
    # That are binded by columns :
    temp_dates = cbind(from_date,to_date)
 
    # temp_dates[,1] = ymd(temp_dates[,1])
    # temp_dates[,2] = ymd(temp_dates[,2])  
    return(temp_dates)
}

SEARCH_DATES_UNDER = function(x){
    temp_names = lapply(x,
                      function(x){x$data$dataseries_name})
    # Uses GET_DATE method to extract dates from datasets :
    temp_dates = SEARCH_DATE(x)
    # print given dates for choice of upper limit :
    print(cbind(temp_dates,temp_names))
    # Get clipboard entry for upper limit :
    date_recherche = as.Date(readline("Enter UPPER DATE LIMIT for selection (without \"\") : \n"))
    # Production of a mask for selection subset :
    mask_date = temp_dates[,1] < date_recherche
    # Subset in return :
    return(x[mask_date])
}

SEARCH_DATES_UPPER = function(x){
    temp_names = lapply(x,function(x){x$data$dataseries_name})
    # Uses GET_DATE method to extract dates from datasets :
    temp_dates = SEARCH_DATE(x)
    # print given dates for choice of lesser limit :
    print(cbind(temp_dates,temp_names))
    # Get clipboard entry for lesser limit :
    date_recherche = as.Date(readline("Enter LOWER DATE LIMIT for selection (without \"\") : \n"))
    # Production of a mask for selection subset :
    # NOTE : 
    # Necessarily consider case where second date is NULL -> thus IFELSE structure
    mask_date = 
      ifelse(!is.na(temp_dates[, 2]), temp_dates[, 2], temp_dates[, 1]) > date_recherche
    # Subset in return :
    return(x[mask_date])
}
```

### By TAGs

```{r SEARCH BY TAGS, echo=TRUE}
# Choose in results which medias to select for download :
SEARCH_TAGS = function(res){
  # Summarize TAGs presents in results :
  # CAUTION : see how "lapply" pattern exposes results to common HDX-Function :
  print(unique(unlist(lapply(res,
                       function(x){get_tags_names(x)}))))
  # Keyboard entry the chosen TAG(s) :
  clef_recherche = readline("Enter TAG for selection : \n")
  # Produce a mask with tag criteria
  mask = unlist(lapply(res,
                       function(x){unlist(sum(get_tags_names(x)==clef_recherche))>=1}))
  # Apply the mask to results for sub-selection : 
  temp_selected = res[mask]
  # Return sub-selection
  return(temp_selected)
}
```

## AGGREGATE search tools

```{r SEARCH IN SELECTION,echo=TRUE}
AGGREG_SEARCH = function(results_pool = NULL, downloading = FALSE){
  if(is.null(results_pool)) {
    # Begin with pooling results on KEYWORD and ROW LIMIT if no arguments passed :
    temp = search_datasets(query = Keyword, rows = rows)
  } else{
    temp = results_pool
  }
  # Use GET_DATE method to extract dates from datasets :
  temp_dates = SEARCH_DATE(temp)
  # Pick items by TAGs :
  temp = SEARCH_TAGS(temp)
  # Cut UPPER TRANCH regarding date argument : 
  temp = SEARCH_DATES_UNDER(temp)
  # Cut LOWER TRANCH regarding date argument : 
  temp = SEARCH_DATES_UPPER(temp)
  
  temp_IDs = lapply(temp,
                    function(x){x$data$id})
  ID = c()
  NAME = c()
  
  for(i in seq(1,length(temp_IDs))){
    ID = append(ID, temp_IDs[[i]])
    temp_dataset = pull_dataset(identifier = ID[i])
    NAME = append(NAME, temp_dataset$data$name)
    eval(parse(
      text = paste0("RESOURCES_dataset_", i, " = get_resources(temp_dataset)")
    ))
    if(downloading == TRUE){
      folder = paste0("C:/Users/Benjamin/Documents/GITHub/HDX_Proj-1/DATAs/TEST/",NAME[i])
      eval(parse(
        text = paste0("dir.create(folder)")
      ))
      eval(parse(
        text = paste0(
          "lapply(RESOURCES_dataset_",
          i,
          ",function(x){x$download(folder = folder)})"
    )))}
  }
  print(cat(paste(ID,NAME,sep = " -> "),sep = "\n"))
}

# temp%>%pluck(1)%>%get_resources()%>%pluck(2)%>%download_resource(folder = folder)

```


```{r EXAMPLE, echo=TRUE}
# Destination folder 
# folder = "C:/Users/Benjamin/Documents/GITHub/HDX_Proj-1/DATAs/From_HDX/"
# Keyword = 'COD Services API'
# rows = 10
# 
# temp = search_datasets(query = Keyword,rows = rows)
# 
# result = temp[[1]]%>%get_resources()
# result[[2]]$download(folder = folder,filename = "PalestinianCommunities_WB_GS_Excel.xlsx")
# 
# stat_results = c()
# districts_results = unique(palest$District)
# 
# prop.table(table(palest[palest$District == districts_list[1],]$Urban_Rurl))
# 
# # Search in selection by TAGs :
# temp_1 = SEARCH_IN_SELECTION(temp)
# 
# # Access to ressources in result : 
# temp_1[[1]]$get_resources()
# 
# temp_IDs = lapply(temp,function(x){x$data$id})
# # execute download :
# download_resource(temp_1[[1]]$get_resources()[[1]],folder = folder)
```

