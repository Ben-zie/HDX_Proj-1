{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9bcb2d3-7f99-4e66-98b1-762699676040",
   "metadata": {},
   "source": [
    "# Search procedure sheet for HDX using Python\n",
    "\n",
    "Set of scripts to install, configure and use Python modules to search in Humanitarian Data eXchange database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f1f5ff0-143f-4805-87e3-b266b884f280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0db0d78-9b6a-480b-88cf-a1cbaa509b20",
   "metadata": {},
   "source": [
    "Load package for regular expression management :      \n",
    "https://docs.python.org/3/library/re.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922e0a81-1230-4d53-82f0-e0b6bd5c176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203d9313-506f-4765-a8f1-c2f64b0742f3",
   "metadata": {},
   "source": [
    "Load package for Humanitarian Data Exchange plateform connexion management (see wiki for links to sources and tutorial) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1414d24f-59d3-45f9-a1d5-060414111513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdx.utilities.easy_logging import setup_logging\n",
    "from hdx.api.configuration import Configuration\n",
    "from hdx.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5e77e1-52f8-4e57-ac90-a4c47740b214",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Setup has to be performed only once :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcb89cf1-7536-4cd6-907c-713bfcdcf3fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "setup_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f32c5010-3508-4c7b-9c70-9a7203096a06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Configuration has to be made only once \n",
    "Configuration.create(hdx_site=\"prod\", user_agent=\"BDAUTRIF_HDX-client-Proj\", hdx_read_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc141cd-7ae3-466b-b021-74bae125319e",
   "metadata": {},
   "source": [
    "## Search \n",
    "\n",
    "Functions for searching in the HDX database (client web-site and tutorials, see wiki). \n",
    "\n",
    "**First, make a configuration** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0f0f5a-443b-4ee4-a4d9-1e9cb383f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = Dataset.search_in_hdx(\"WHO\", rows=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9a4cc2-1ec6-4f80-883d-da09240087c6",
   "metadata": {},
   "source": [
    "More parameters avalilable by \"get_*\" methods of Dataset object :        \n",
    "See :            \n",
    "https://github.com/Ben-zie/HDX_Proj-1/blob/main/Python_HDX-Proj-1.ipynb\n",
    "\n",
    "**Stock \"results\" in a dataframe** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7729566b-ccba-4a86-9228-b9128c50da2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac99958-1934-4475-b388-af3be06ff316",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Variables in the 'result' dataframe :\n",
    "\n",
    " Several variables are available in results when inserted in a dataframe :\n",
    "\n",
    "|FIELD|TYPE|FIELD|TYPE|\n",
    "|--|--|--|--|\n",
    "|archived                              |bool|maintainer                          |object|\n",
    "|batch                               |object|metadata_created                    |object|\n",
    "|caveats                             |object|metadata_modified                   |object|\n",
    "|cod_level                           |object|methodology                         |object|\n",
    "|creator_user_id                     |object|methodology_other                   |object|\n",
    "|customviz                           |object|name                                |object|\n",
    "|data_update_frequency               |object|notes                               |object|\n",
    "|dataseries_name                     |object|num_resources                        |int64|\n",
    "|dataset_date                        |object|num_tags                             |int64|\n",
    "|dataset_preview                     |object|organization                        |object|\n",
    "|dataset_source                      |object|overdue_date                        |object|\n",
    "|due_date                            |object|owner_org                           |object|   \n",
    "|groups                              |object|package_creator                     |object|\n",
    "|has_geodata                           |bool|pageviews_last_14_days               |int64|\n",
    "|has_quickcharts                       |bool|private                               |bool|\n",
    "|has_showcases                         |bool|qa_checklist                        |object|\n",
    "|id                                  |object|qa_completed                          |bool|\n",
    "|indicator                           |object|quality                             |object|\n",
    "|is_requestdata_type                   |bool|relationships_as_object             |object|\n",
    "|isopen                                |bool|relationships_as_subject            |object| \n",
    "|last_modified                       |object|review_date                         |object|\n",
    "|license_id                          |object|solr_additions                      |object| \n",
    "|license_other                       |object|state                               |object| \n",
    "|license_title                       |object|subnational                         |object| \n",
    "|license_url                         |object|tags                                |object| \n",
    "|title                               |object|updated_by_script                   |object|\n",
    "|total_res_downloads                  |int64|url                                 |object|\n",
    "|type                                |object|version                             |object|\n",
    "|date_var                        |datetime64|                        || \n",
    "\n",
    "Methods exist to get infos and parameters from a specific dataset (see further in this article). Following scripts aim to get informations and selections directly from a list of results from a research.\n",
    "\n",
    "# Sort results \n",
    "\n",
    "## By keyword :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78186746",
   "metadata": {},
   "source": [
    "**SOURCE : online python course on KAGGLE plateform** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6284ac33-cf21-4624-9e02-77057c9a4411",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def word_search(datasets_list, patern, field=None):\n",
    "    \"\"\"\n",
    "    Desc : function to search a (unique) KEYWORD in a field\n",
    "    Input :  a LIST of textual documents (here NOTES categorie of a DATASET_LIST) + a KEYWORD to look after in each\n",
    "    Output : a LIST of indexes of KEYWORD matching documents\n",
    "    \"\"\"\n",
    "    \n",
    "*# list to hold the indices of matching documents\n",
    "    indices = [] \n",
    "    datasets_list_field = datasets_list[field]\n",
    " # Iterate through the indices (i) and elements (doc) of documents\n",
    "    for i, dataset in enumerate(datasets_list_field):\n",
    " # Split the string doc into a list of words (according to whitespace)\n",
    "        tokens = dataset.split()\n",
    " # Make a transformed list where we 'normalize' each word to facilitate matching.\n",
    " # Periods and commas are removed from the end of each word, and it's set to all lowercase.\n",
    "        normalized = [token.rstrip('.,').lower() for token in tokens]\n",
    " # Is there a match ? If so, update the list of matching indices.\n",
    "        if patern.lower() in normalized:\n",
    "            indices.append(i)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa163a1-d0d3-4cfa-9ee7-ba555196e707",
   "metadata": {},
   "source": [
    "## SORTING BY DATE MODULE :\n",
    "*Using package \"re\" for regular expressions :*\n",
    "\n",
    "Set a function to get the dataset date from ['dataset_date'] (for datasets referenced by an intervall period, the last one is chosen) and returned as a vector :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a554d3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_date (x): \n",
    "    \"\"\"\n",
    "    Function : sets a DATE_BEFORE_VAR and a DATE_AFTER_VAR colums to dataset\n",
    "    Those are date-formated : %Y-%m-%d\n",
    "    Parameters : a dataframe containing research results from the HDX databse\n",
    "    Returns : dates of different datasets in a vector object\n",
    "    \"\"\"\n",
    "# Extract column from results dataset :\n",
    "    x_dates = x.get('dataset_date')\n",
    "# Get the pattern of each dates (FROM / TO) :\n",
    "# TODO : verify compatibility with database regarding from positionning in singles\n",
    "    x_dates = x_dates.str.findall(r'(\\d{4}-\\d{2}-\\d{2})T')\n",
    "# 'Serialize' the two columns :\n",
    "    x_dates = x_dates.apply(lambda x : pd.Series(x))\n",
    "# Insert it in the original dataset :\n",
    "    x['date_before_var'] = pd.to_datetime(x_dates[0],)\n",
    "    x['date_after_var']  = pd.to_datetime(x_dates[1],)\n",
    "# Which we return :\n",
    "    print(\"set_date all done\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c8188a",
   "metadata": {},
   "source": [
    "**Set a function to add a variable to dataset, containing date and sort dataset by this column** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb690ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_date (x, ascending=True, inplace = False) :\n",
    "    \"\"\"\n",
    "    Function : Sorts a dataset by dates. Mainly a filter for 'select_by_date' function.\n",
    "    Parameters : a dataframe containing research results from the HDX databse\n",
    "    Returns : given dataset sorted by the last entry date in datas\n",
    "    \"\"\"\n",
    "# Call the 'set_date' function to have right columns to look in :\n",
    "    x = set_date(x)\n",
    "# Use formated columns to sort dataset with :\n",
    "    x = x.sort_values(by='date_before_var', ascending = ascending, inplace = inplace)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb0c64d",
   "metadata": {},
   "source": [
    "**Aggregated time-searching functions** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a55df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_by_date (results,\n",
    "                    start_date,\n",
    "                    end_date,\n",
    "                    ascending = False,\n",
    "                    inplace = False) :\n",
    "    # From the 'results' dataset, set and sort the dates in formated columns :\n",
    "    x = sort_by_date(results, ascending = ascending)\n",
    "    # Cases for search FROM, TO or IN BETWEEN dates :\n",
    "    if start_date != None and end_date != None :\n",
    "        # Select DataFrame rows between two dates using DataFrame.isin()\n",
    "        y = x[x[\"date_after_var\"].isin(pd.date_range(start_date, end_date))]\n",
    "        print('option 1 : find items in interval')\n",
    "        # Source : https://sparkbyexamples.com/pandas/pandas-select-dataframe-rows-between-two-dates/\n",
    "    elif start_date != None :\n",
    "        # Selecting lower to the limit-date :\n",
    "        mask = (x['date_after_var'] > start_date)\n",
    "        y = x[mask]\n",
    "        print('option 2 : find items upper the limit-date')\n",
    "    elif end_date != None :\n",
    "        # Selecting upper to the limit-date :\n",
    "        mask = (x['date_after_var'] < end_date)\n",
    "        y = x[mask]\n",
    "        print('option 3 : find items lower the limit-date')\n",
    "    else : \n",
    "        # No limit-date to search for\n",
    "        print('no limits pointed for selection')\n",
    "        y=None\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ff16b5-0afd-4f51-8631-5c0e5955693e",
   "metadata": {},
   "source": [
    "## By type :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f3563d-3e69-41d4-b27a-b7b47061fbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_geodata (x, y) :\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : dataframe (pandas)\n",
    "        Source dataframe generated with results elements\n",
    "    y : bool\n",
    "        A boolean which tell if (Yes / No) you want to select elements corresponding to geodatas\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x : dataframe\n",
    "        Items found in HDX (from results passed in arguments) that correspond / dont correspond to geodatas.\n",
    "\n",
    "    \"\"\"\n",
    "    x = x[x['has_geodata'] == y]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5682c0-7397-4f09-8e8f-1117ee9b78f5",
   "metadata": {},
   "source": [
    "## By source :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bfacfe-a316-4e95-beaf-5ace9176d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_sources (x) :\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : dataframe\n",
    "        dataframe generated with reluts of a research in the HDX database.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tmp : list\n",
    "        list of each sources presents in the results.\n",
    "\n",
    "    \"\"\"\n",
    "    tmp = []\n",
    "    pool_sources = x.dataset_source\n",
    "    for i in pool_sources : tmp.append(re.findall(r'[^,]+(?=,|$)', i))\n",
    "    tmp = list(np.concatenate(tmp))\n",
    "    tmp = list(set(tmp))\n",
    "    return tmp\n",
    "\n",
    "\n",
    "def select_sources (x, y) :\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : dataframe\n",
    "        dataframe generatied with results of a research in the HDX database.\n",
    "    y : str\n",
    "        pattern to look for in the sources.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        selection of items containing y in theire sources.\n",
    "\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for i in range(0,len(x)) :\n",
    "        tmp = re.search(y, x.loc[i].dataset_source)\n",
    "        if tmp :\n",
    "            res.append(i)\n",
    "    return x.loc[res]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554316cc-f482-4602-8e32-9edd9244a613",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read module :\n",
    "\n",
    "Read dataset and get ressources :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8a91d32-87a1-498f-a393-3f5909014558",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'startdate': datetime.datetime(2020, 1, 22, 0, 0, tzinfo=datetime.timezone.utc), 'enddate': datetime.datetime(2023, 3, 9, 23, 59, 59, tzinfo=datetime.timezone.utc), 'startdate_str': '2020-01-22T00:00:00+00:00', 'enddate_str': '2023-03-09T23:59:59+00:00', 'ongoing': False}\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.read_from_hdx(\"novel-coronavirus-2019-ncov-cases\")\n",
    "print(dataset.get_reference_period())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3bc34362-7a9f-4767-9bb3-d07c78a43e98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "period = dataset.get_reference_period()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2e582c8-3918-4255-ab0b-03d9a76b3ed3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "locations = dataset.get_location_iso3s()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a015a91b-83aa-4234-95ea-c7da808ccb30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "locations = dataset.get_location_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b26c8b1b-ea5a-4092-8f8f-9758c6ef654c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tags = dataset.get_tags()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (HDX_Proj)",
   "language": "python",
   "name": "hdx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
